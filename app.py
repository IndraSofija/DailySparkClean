from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from dotenv import load_dotenv
import os
import logging

import requests

try:
    response = requests.get("https://api.openai.com/v1/models", timeout=5)
    print("âœ… Railway var sasniegt OpenAI API. Statusa kods:", response.status_code)
except requests.exceptions.RequestException as e:
    print("âŒ Railway NEVAR sasniegt OpenAI API:", e)

# IelÄdÄ“ .env mainÄ«gos
load_dotenv()

# InicializÄ“ FastAPI
app = FastAPI()

# AtÄ¼aut visus CORS pieprasÄ«jumus (frontenda testÄ“Å¡anai)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Logging iestatÄ«jumi
logging.basicConfig(level=logging.INFO)

# ğŸ” Debug: pÄrbaudi, vai API_KEY vispÄr tiek saÅ†emts
api_key = os.getenv("OPENAI_API_KEY")
print("ğŸ” API key (sÄkums):", api_key[:10] if api_key else "None")

client = OpenAI()


@app.get("/")
def root():
    return {"message": "DailySpark backend is running."}

@app.post("/generate")
async def generate_text(request: Request):
    logging.info("ğŸš€ API /generate saÅ†emts!")

    try:
        body = await request.json()
        prompt = body.get("prompt")

        if not prompt:
            return {"error": "Prompt is required."}

        # âœ… JAUNÄ€S API SINTAKSES IZMANTOJUMS
        chat_completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        result = chat_completion.choices[0].message.content.strip()
        return {"result": result}

    except Exception as e:
        logging.error(f"âš ï¸ KÄ¼Å«da Ä£enerÄ“Å¡anas laikÄ: {e}")
        return {"error": str(e)}
